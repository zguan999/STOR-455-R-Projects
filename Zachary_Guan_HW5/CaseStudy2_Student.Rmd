---
title: "Case Study 2: University tuition"
author: "Kelly Bodwin"
output: html_document
---

## Get the data

We will be attempting to find a linear regression that models college tuition rates, based on a dataset from US News and World Report.  Alas, this data is from 1995, so it is very outdated; still, we will see what we can learn from it.

*****
### Question 1:

a) The dataset is located at `http://kbodwin.web.unc.edu/files/2016/09/tuition_final.csv`; figure out how to use the code you were given last time for `read.csv( )` and `read.table( )` to read the data into **R** and call it `tuition`. Use the functions we learned last time to familiarize yourself with the data in `tuition`. 

```{r, eval = TRUE}
  # YOUR CODE HERE
tuition = read.csv("http://kbodwin.web.unc.edu/files/2016/09/tuition_final.csv")



```

b) Make a new variable in `tuition` called `Acc.Rate` that contains the acceptance rate for each university.

```{r, eval = TRUE}
  # YOUR CODE HERE
tuition$Acc.Rate<- tuition$Accepted/tuition$Applied

```

c) Find and print the row of the data that corresponds to UNC ("University of North Carolina at Chapel Hill").

```{r, eval = TRUE}
  # YOUR CODE HERE
tuition[tuition$Name == "University of North Carolina at Chapel Hill",]
```

*****
## Writing functions

We have seen many examples of using functions in **R**, like `summary( )` or `t.test( )`.  Now you will learn how to write your *own* functions.  Defining a function means writing code that looks something like this:

```{r, eval = FALSE}

my_function <- function(VAR_1, VAR_2){
  
  # do some stuff with VAR_1 and VAR_2
  return(result)
  
}

```

Then you run the code in **R** to "teach" it how your function works, and after that, you can use it like you would any other pre-existing function.  For example, try out the following:

```{r, eval = FALSE}

add1 <- function(a, b){
  
  # add the variables
  c = a + b
  return(c)
  
}

add2 <- function(a, b = 3){
  
  # add the variables
  c = a + b
  return(c)
  
}

# Try adding 5 and 7
add1(5, 7)
add2(5, 7)

# Try adding one variable
add1(5)
add2(5)

```
****

### Question 2:
What was the effect of `b = 3` in the definition of `add2( )`?

```
instantiates variable b with number 3. The value 3 is stored in b so if no input is provided b defaults to 3. 
```

****

### Question 3:
a) Recall that the equations for simple linear regression are:
$$\beta_1 = r \frac{S_Y}{S_X} \hspace{0.5cm} \beta_0 = \bar{Y} - \beta_1 \bar{X}$$

Write your own functions, called `beta1( )` and `beta0( )` that take as input some combination of `Sx`, `Sy`, `r`, `y_bar`, and `x_bar`, and use that to calculate $\beta_1$ and $\beta_0$.

```{r, eval = TRUE}
  # YOUR CODE HERE
beta1 <- function(Sx, Sy, r) {
  
  return (r*(Sy/Sx))
}

beta0 <- function(Sx, Sy, r ,y_bar,x_bar) {
  if (Sx == 0) {
    return (NaN) 
  } else{
    b1 = beta1(Sx,Sy,r)
    return (y_bar - b1*x_bar)
  }
  
}



```

b) Try your function with `Sx = 0`.  Did it work?  If not, fix your function code.  Explain why it would be a problem to do linear regression with $S_X = 0$.

```
Dividing by 0 creates infinite. When calculating Beta 1 , dividing the std dev of y by a zero will not create a linear model;

```

****

## Linear Regression by hand

Use the code below to make a scatterplot of college tuition versus average SAT score.

```{r, eval = TRUE}

plot(tuition$Avg.SAT, tuition$Out.Tuition, main = "title", xlab = "label", ylab = "label", pch = 7, cex = 2, col = "blue")

```

*****
### Question 4:
a) Make your own scatterplot, but change the input of `plot( )` so that it looks nice. 

```{r, eval = TRUE}
  # YOUR CODE HERE
plot(tuition$Avg.SAT, tuition$Out.Tuition, main = "Scatterplot of Tuition vs. SAT Scores", xlab = "SAT score", ylab = "Tuition", pch = 4, cex = .5, col = "blue")

```


b) What do `pch` and `cex` do?

```
"cex changes the size of each point in the scatter plot and scales it based on the value. pch changes the symbol for each point"
```

c) We have used the function `abline( )` to add a vertical line or a horizontal line to a graph.  However, it can also add lines by slope and intercept.  Read the documentation of `abline( )` until you understand how to do this.  Then add a line with slope 10 and intercept 0 to your plot.  
```{r, eval = TRUE}
  # YOUR CODE HERE
plot(tuition$Avg.SAT, tuition$Out.Tuition, main = "Scatterplot of Tuition vs. SAT Scores", xlab = "SAT score", ylab = "Tuition", pch = 4, cex = .7, col = "blue")

abline(a = 0, b = 10)
```

d) Does this line seem to fit the data well?

```
"The line does fit the data partially but needs adjustment to reflect a more accurate linear regression. "
```

****

### Question 5:
a) Use the functions you already know in **R** and the ones you created, `beta1( )` and `beta0( )`, to find the slope and intercept for a regression line of `Avg.SAT` on `Out.Tuition`.  Remake your scatterplot, and add the regression line.

*(Hint:  You may have some trouble finding the mean and sd because there is some missing data.  Look at the documentation for the functions you use.  What could we add to the function arguments to ignore values of `NA`?)*

```{r, eval = TRUE}
  # YOUR CODE HERE
avg_sd = sd(tuition$Avg.SAT,na.rm = TRUE)
avg_mean = mean(tuition$Avg.SAT, na.rm =TRUE)
out_sd = sd(tuition$Out.Tuition, na.rm = TRUE)
out_mean = mean(tuition$Out.Tuition, na.rm=TRUE)
r_value = cor(tuition$Avg.SAT, tuition$Out.Tuition,us = "pairwise.complete.obs")

b0= beta0(avg_sd,out_sd,r_value,out_mean,avg_mean)
b1= beta1(avg_sd,out_sd, r_value)

plot(tuition$Avg.SAT, tuition$Out.Tuition, main = "Scatterplot of Tuition vs. SAT Scores", xlab = "SAT score", ylab = "Tuition", pch = 4, cex = .7, col = "blue")

abline(a = b0, b = b1, col = "red", lw = 2)


```

b) What do you conclude about the relationship between average SAT score and a college's tuition?

```
"there seems to be a positive linear correlation between SAT scores and college tuition"

```

****

### Question 6:
a) Write a new function called `predict_yval(X, Y, x_new)` that takes as input a vector of explanatory variables (`X`), a vector of y-variables (`Y`), and a new x-value that we want to predict (`x_new`).  The output of the function should be the predicted y-value for `x_new` from a regression line. *(Hint: You can use functions inside functions.)*

```{r, eval = TRUE}

predict_yval <- function(X, Y, x_new){
x_mean = mean(X,na.rm = TRUE)
y_mean = mean(Y, na.rm =TRUE)
x_sd = sd(X, na.rm = TRUE)
y_sd = sd(Y, na.rm=TRUE)

r_value = cor(X, Y ,us = "pairwise.complete.obs") 

b0= beta0(x_sd,y_sd,r_value,y_mean,x_mean)
b1= beta1(x_sd,y_sd,r_value)

y_new = b0+b1*x_new
   
return(y_new )
  
}

```

b) Now find the average SAT score and tuition of UNC and of Duke, and compare their predicted values to the truth:

```{r, eval = TRUE}
  # YOUR CODE HERE
unc = tuition[tuition$Name == "University of North Carolina at Chapel Hill",]
duke = tuition[tuition$Name == "Duke University",]

unc_pred= predict_yval(tuition$Avg.SAT,tuition$Out.Tuition,unc$Avg.SAT)
duke_pred =predict_yval(tuition$Avg.SAT,tuition$Out.Tuition,duke$Avg.SAT)

print(unc_pred)
duke_pred

"Dukes Predicted Tuition over $5000 more than the tuition of UNC"

 

```

c) Would you say you are getting a deal at UNC?  How about at Duke?

```
"I would say that UNC is a a deal whereas Duke is not."
```
***

### `lm()` and diagnostics

You now have functions to calculate the slope and intercept of a linear regression, and to predict values. As you might expect, **R** was already able to do this, using the function `lm( )`.  In class, you saw how to read the output of `lm( )`.  Run the following regression of `Avg.SAT` on `Out.Tuition`, and refamiliarize yourself with the output.

```{r, eval = FALSE}
  
  # Make linear model
  my_lm = lm(Out.Tuition ~ Avg.SAT, data = tuition)
  summary(my_lm)

```

Check out `names(my_lm)`.  This will give you a list of information we can access using `$`.  For example, compare `my_lm$coefficents` to your `beta1` and `beta0` outputs.

The output of `lm( )` is made to play nicely with other functions in **R**. For example, try adding `abline(my_lm)` to your scatterplot.  We can also use `lm( )` to check some common diagnostics, to see if the linear model is a good fit for the data.  Try `plot(my_lm)`, and familiarize yourself with the first three plots that are automatically generated.  (The fourth is not covered in this course, so you do not need to worry about it for now.)

